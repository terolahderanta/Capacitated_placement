---
title: "Probabilistic Clustering"
author: "Tero Lähderanta, Lauri Lovén"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Probabilistic Clustering}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 4,  
  collapse = TRUE,
  comment = "#>"
)
```

This vignette provides a tutorial on main functionality of the `pclustr` package.

## Libraries

First, load the necessary libraries. In addition to the `pclustr` package, we use 
`tidyverse` and `dplyr` for sample data manipulation and  `ggplot2` for plotting.

```{r, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
library(pclustr)
library(tidyverse)
library(dplyr)
library(ggplot2)
```


## Simulated data 

Let's set up some data to be clustered. 

```{r data, include=TRUE, echo = TRUE}
set.seed(5)

dat <- tibble(
  x1 = c(stats::rnorm(50, mean = 1.5, sd = 0.8), 
         stats::rnorm(50, mean = 5.5, sd = 0.8),
         stats::rnorm(50, mean = 3.0, sd = 0.8), 
         stats::rnorm(50, mean = 4.5, sd = 0.8), 8),
  x2 = c(stats::rnorm(50, mean = 1.0, sd = 0.8), 
         stats::rnorm(50, mean = 1.5, sd = 1.0),
         stats::rnorm(50, mean = 4.5, sd= 1.0), 
         stats::rnorm(50, mean = 4.5, sd = 0.8), 6),
  w =  round(stats::runif(201, min = 0.51, max = 10.49)),
  id = 1:201
)

ggplot(
  data = dat, 
  mapping =
    aes(x = x1,
        y = x2,
        size = w)
) +
  geom_point() +
  scale_size(range = c(2, 7)) +  # Scale objects sizes
  guides(
    color = guide_legend(        # Point size in legend
      override.aes = list(size=5)
    )
  ) +
  labs(x = "x1", y = "x2", title = "Unclustered data") +
  theme(
    legend.position = "right",            # Legend position and removing ticks from axis
    axis.text.x = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank()
  ) 
```

Bigger datasets take a bit longer to cluster. To get a hang of the required processing times, you could try also the following sets:

```{r bigger_data, echo = TRUE, include = TRUE}
dat_500 <- tibble(
  x1 = c(stats::rnorm(100, mean = 0.5, sd = 2), 
         stats::rnorm(150, mean = 23.5, sd = 5),
         stats::rnorm(100, mean = 2.0, sd = 6), 
         stats::rnorm(150, mean = 5.5, sd = 2)),
  x2 = c(stats::rnorm(100, mean = 0.5, sd = 2), 
         stats::rnorm(150, mean = 1.0, sd = 7.5),
         stats::rnorm(100, mean = 20.5, sd= 5.5),
         stats::rnorm(150, mean = 5.5, sd = 2)),
  w =  round(stats::runif(500, min = 0.51, max = 10.49)),
  id = 1:500
)

dat_1000 <- tibble(
  x1 = c(stats::rnorm(250, mean = 0.5, sd = 2), 
         stats::rnorm(250, mean = 21.5, sd = 3),
         stats::rnorm(250, mean = 2.0, sd = 6), 
         stats::rnorm(250, mean = 5.5, sd = 2)),
  x2 = c(stats::rnorm(250, mean = 0.5, sd = 2), 
         stats::rnorm(250, mean = 1.0, sd = 7.5),
         stats::rnorm(250, mean = 20.5, sd= 5.5), 
         stats::rnorm(250, mean = 5.5, sd = 2)),
  w =  round(stats::runif(1000, min = 0.51, max = 10.49)),
  id = 1:1000
)
```



## Clustering with uniform prior, k=10

First, cluster the data into k=10 clusters with a uniform prior for the cluster weights. In other words, 
we let the total weights of clusters vary uniformly within a given range. We set the
range as the mean of object weight +- 20.

```{r uniform_clustering, include=TRUE, echo = TRUE}

# Number of clusters
k <- 10

# Mean
pr_mean <- round(sum(dat$w) / k)

# Max radius for prior
pr_width <- 20

# Lower und upper limit for cluster size
L <- (pr_mean - pr_width)
U <- (pr_mean + pr_width)

# FIXME: Explain lambda1
lambda1 <- 5

# Initialize cluster centers with kmeans
init_kmpp <- kmpp(cbind(rep(dat$x1, dat$w),
                        rep(dat$x2, dat$w)),
                  k)
init_mu <- init_kmpp$centers

# Cluster
clust <- prob_clust(
  data = dat %>% select(x1, x2),
  weights = dat$w,
  k = k,
  init_mu = init_mu,
  prior_dist = "uniform",
  range = c(L, U),
  lambda = lambda1
)

dat$cl <- clust[[1]]
mu <- clust[[2]]
obj_min <- clust[[3]]
```

Plot the clusters with `plot_clusters`.
```{r uniform_clusterplot, echo=TRUE, include=TRUE}
plot_clusters(
  x = dat %>% dplyr::pull(x1),
  y = dat %>% dplyr::pull(x2),
  weights = dat$w,
  clusters = dat$cl,
  mu = mu,
  title = paste("Probabilistic clustering, k = ", k, sep = ""),
  subtitle = paste("Uniform prior in [", L, ", ", U, "] on cluster weights", sep = "")
)
```

## Clustering with Gaussian prior, k=10

Second, cluster the data into k=10 clusters with a Gaussian prior for the cluster weights. In other words, 
we let the total weights of clusters vary normally, setting the standard deviation as 3.

```{r gaussian_clustering, include=TRUE, echo = TRUE}
   
pr_sd <- 3

clust <-
  prob_clust(
    data = dat %>% select(x1, x2),
    weights = dat$w,
    k = k,                # already set as 10
    init_mu = init_mu,    # use the same initial centers as above
    prior_dist = "normal",
    sigma = pr_sd
  )
dat$cl <- clust[[1]]
mu <- clust[[2]]
```

Plot the clusters.

```{r gaussian_clusterplot, include=TRUE, echo=TRUE}
plot_clusters(
  x = dat %>% pull(x1),
  y = dat %>% pull(x2),
  weights = dat$w,
  clusters= dat$cl,
  mu = mu,
  title = paste("Probabilistic clustering, k = ", k, 
                sep = ""),
  subtitle = paste("Gaussian prior on cluster weights (sd = ", pr_sd, ")", 
                   sep = "")
) 
```
