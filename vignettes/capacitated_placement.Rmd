---
title: "Capacitated Placement"
author: "Tero Lähderanta, Lauri Lovén, Leena Ruha"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Capacitated Placement}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 4,  
  collapse = TRUE,
  comment = "#>"
)
```

This vignette provides a tutorial on main functionality of the `rpack` package.

## Libraries

First, load the necessary libraries. In addition to the `rpack` package, we use 
`tidyverse` and `dplyr` for sample data manipulation and  `ggplot2` for plotting.

```{r, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
library(rpack)
library(tidyverse)
library(dplyr)
library(ggplot2)
```


## Simulated data 

Let's set up some data to be clustered. 

```{r data, include=TRUE, echo = TRUE}

set.seed(112)

# Generating 300 points from mixture of 10 normal distributions.
test_dat <- simulate_normal_mixture(n = 300, k = 10)

ggplot(data = test_dat, aes(x = x, y = y, size = w)) +
  geom_point() +
  scale_size(range = c(2, 6)) +  # Scale objects sizes
  guides(
    color = guide_legend(        # Point size in legend
      override.aes = list(size=5)
    )
  ) +
  labs(x = "x", y = "y", title = "Unclustered data") +
  theme(
    legend.position = "right",            # Legend position and removing ticks from axis
    axis.text.x = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank()
  )

```

Bigger datasets take a bit longer to cluster. To get a hang of the required processing times, you could try also the following sets:

```{r bigger_data, echo = TRUE, include = TRUE}

set.seed(112)

# Generating 500 points from mixture of 20 Laplace distributions.
test_dat2 <- simulate_laplace_mixture(n = 500, k = 20)

# Generating 1000 points from mixture of 25 normal distributions.
test_dat3 <- simulate_normal_mixture(n = 1000, k = 25)

```



## Clustering with uniform prior

First, cluster the data into $k=10$ clusters with a uniform prior for the cluster weights. In other words, 
we let the total weights of clusters vary uniformly within a given range. We set the
range as $mean(w) \pm 100 $.

k = 10
uniform prior for the weights
range: mean of object weight +- 100
place_to_point = FALSE
distance = euc_dist2
no outliers

```{r uniform_clustering, include=TRUE, echo = TRUE}

# Number of clusters
k <- 10

# Mean
pr_mean <- round(sum(test_dat$w) / k)

# Max radius for prior
pr_width <- 100

# Lower und upper limit for cluster size
L <- (pr_mean - pr_width)
U <- (pr_mean + pr_width)

# Alternaring algorithm
clust <- alt_alg(
  coords = dplyr::select(test_dat, x, y),
  weights = test_dat$w,
  N = 2,
  k = k,
  range = c(L, U),
  place_to_point = FALSE
)

# Save the results of the clustering.
test_dat$cl <- clust$clusters
mu <- clust$centers
obj_min <- clust$obj
```

Plot the clusters with `plot_clusters`.
```{r uniform_clusterplot, echo=TRUE, include=TRUE}
plot_clusters(
  coords = test_dat[,1:2],
  weights = test_dat$w,
  clusters = test_dat$cl,
  mu = mu,
  title = paste("Capacitated clustering, k = ", k, sep = ""),
  subtitle = paste("Uniform prior in [", L, ", ", U, "] on cluster weights", sep = "")
)
```

## Clustering with limitations to center locations and adding outgroup for the data points.

Similarly, cluster the data into $k=10$ clusters, but limit the cluster heads to chosen from the set of data points. In addition, add outgroup for the data points. Outgroup consists of points that can be seen as outliers from other points and are not allocated to any of the clusters. 

```{r uniform_clustering_out, include=TRUE, echo = TRUE}

# Number of clusters
k <- 10

# Mean
pr_mean <- round(sum(test_dat$w) / k)

# Max radius for prior
pr_width <- 100

# Lower und upper limit for cluster size
L <- (pr_mean - pr_width)
U <- (pr_mean + pr_width)

# Outgroup parameter lambda, smaller value --> more outliers
lambda1 <- 0.016

# Alternaring algorithm
clust2 <- alt_alg(
  coords = dplyr::select(test_dat, x, y),
  weights = test_dat$w,
  N = 2,
  k = k,
  range = c(L, U),
  place_to_point = TRUE, # Cluster heads is chosen from the data points
  lambda = lambda1
)

```

Plot the clusters. Outgroup points are labeled as "NA".
```{r uniform_clusterplot_out, echo=TRUE, include=TRUE}
plot_clusters(
  coords = test_dat[,1:2],
  weights = test_dat$w,
  clusters = clust2$clusters,
  mu = clust2$centers,
  title = paste("Capacitated clustering, k = ", k, sep = ""),
  subtitle = paste("Uniform prior in [", L, ", ", U, "] on cluster weights", sep = "")
)
```

## Clustering with different distance metric.

Once again, cluster the data into $k=10$ clusters, but calculate the distance between points as Euclidean distance instead of default squared Euclidean distance. Euclidean distance measure minimizes the physical distance between points and the center in a cluster, while squared Euclidean distance forms more spherical-like clusters.

```{r uniform_clustering_euc_dist, include=TRUE, echo = TRUE}

# Number of clusters
k <- 10

# Mean
pr_mean <- round(sum(test_dat$w) / k)

# Max radius for prior
pr_width <- 100

# Lower und upper limit for cluster size
L <- (pr_mean - pr_width)
U <- (pr_mean + pr_width)

# Alternaring algorithm
clust3 <- alt_alg(
  coords = dplyr::select(test_dat, x, y),
  weights = test_dat$w,
  N = 2,
  k = k,
  range = c(L, U),
  place_to_point = TRUE,
  d = euc_dist # Input for distance metric is in a form of a function.  
)

```

Plot the clusters.
```{r uniform_clusterplot_euc_dist, echo=TRUE, include=TRUE}
plot_clusters(
  coords = test_dat[,1:2],
  weights = test_dat$w,
  clusters = clust3$clusters,
  mu = clust3$centers,
  title = paste("Capacitated clustering, k = ", k, sep = ""),
  subtitle = paste("Uniform prior in [", L, ", ", U, "] on cluster weights", sep = "")
)
```
